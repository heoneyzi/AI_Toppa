안녕하세요. 지나가던 사람입니다.
지나가는 김에, 제가 AI에 대해 조금 맛봤던 정보들을 살짝 놓고 가려고요.
가볍게 보시고 지나가주시면 감사하겠습니다.

---

### 인공지능
##### Artificial Intelligence
이름이 굉장히 직관적이죠.
인간이 만든 지능.

그렇다면 '지능'은 정확하게 무엇을 나타내는 걸까요?

표준국어대사전에 의하면 '지능'은 다음과 같이 정의됩니다.

_계산이나 문장 작성 따위의 **지적 작업에서**, 성취 정도에 따라 정하여지는 적응 능력. 지능 지수 따위로 수치화할 수 있다._

'지적 작업'에는 문제 해결뿐만 아니라, 추론, 언어 이해, 학습 등의 다양한 사고 활동이 포함됩니다. 그중 문제 해결은 대표적인 지능의 표현으로 볼 수 있죠.
문제 해결에도 효율적인 방법과 자원이 더 들어가게 되는 비효율적인 방법으로 나뉩니다.
AI 시스템은 단지 문제를 푸는 것뿐 아니라, 계산 자원과 시간 등을 최소화하며 문제를 해결할 수 있어야 합니다. 이런 효율성 역시 지능의 중요한 부분입니다.
가능한 효율적인 방법을 선호할 것입니다. 저희가 가진 자원은 언제나 유한하니까요.

쉽게 얘기하자면,
지능은 똘똘함입니다.
단순히 계산을 잘하는 것뿐 아니라, **새로운 문제를 유연하게 접근하고, 배운 것을 응용하는 능력까지 포함한 '효율성을 추구하는 똘똘함'**이죠.

생물학적 진화를 통해 고도의 지능을 갖게 된 인류는,
그 지능을 기계에도 담아내고 싶었습니다.
그리고 성공했고요.

이 진보는 벌써 궤도에 올라왔습니다.
어떻게 이런 진보가 가능했는지, 지능을 어떻게 구현할 수 있게 됐는지 알고 싶었습니다.
그래서 산발적이지만, AI를 이해하는 데 필수적인 개념들을 한 번 정리해보고자 합니다.

---

### 머신러닝
#### Machine Learning

직역하자면 기계 학습이죠.
정확한 의미를 이해하기 위해, 구글에서 정의한 머신러닝을 살펴보겠습니다.

![](https://velog.velcdn.com/images/suhwan0823/post/c9abfe3c-70f2-430f-bf5f-4235feea9a19/image.png)


기존 컴퓨터나 프로그래밍의 본질은
**저희가 일일이 규칙을 만들어서 입력값에 대해서 원하는 출력값을 얻고자 하는 것이었습니다.**

하지만 그럴 필요가 없어졌습니다.
왜냐하면 인류는 정말 상상할 수 없을 정도로 방대한 데이터들을 축적돼있기 때문이죠.
텍스트, 이미지, 영상, 센서 정보, 사용 기록 등 다양한 형태의 데이터가 인터넷과 디지털 기기를 통해 매일 생성되고 있으니까요.

그래서 이제 어떻게 하느냐?
**시스템이 데이터를 바탕으로 입력과 출력 사이의 _패턴(함수)_ 을 스스로 학습해내는 것이죠. 
다시 말해, 사람이 일일이 규칙을 짜지 않아도, 알고리즘이 데이터를 통해 ‘어떻게 출력이 나오는지’를 스스로 추론하는 것입니다.**

기존 컴퓨터나 프로그래밍과 비교해서 뭐가 더 대단한거지? 싶을 수 있습니다.
하지만, 이는 정말 대단한 것입니다.
기존의 프로그래밍은 사람이 직접 규칙을 명시할 수 있는 정형화된 문제에 특화되어 있었습니다. 
반면, 머신러닝은 복잡하고 불명확한 패턴을 가진 비정형 문제를 다루는 데 강점을 보이죠.

그렇다면 슬슬 궁금해집니다. 이것들이 어떻게 가능해졌을까요?
규칙을 만드는 과정에는 어떤 개념들이 숨어 있을까요?
하나씩, 가볍게 들여다보겠습니다.

---
### 딥러닝
#### Deep Learning

딥러닝(Deep Learning)은 머신러닝의 한 분야로, **인공 신경망(ANN: Artificial Neural Network)** 을 깊게 쌓아 학습하는 방식입니다.
다시 말해 사람의 두뇌를 모방한다는 뜻이죠.
인공 신경망은 뉴런의 역할을 한다고 이해하면 됩니다.
좀 더 구체적으로 말하면, 하나의 '노드'(node)가 뇌의 뉴런처럼 동작하고, 이 노드들이 모여 하나의 '층'(layer)을 이루며, 여러 층이 차례로 연결된 구조가 인공 신경망입니다.

조금 딥하게 들어가보자면...
입력 데이터가 각 층을 통과하며 연산되고, 마지막에 나오는 결과와 정답을 비교해 오차를 계산합니다. 이를 **역전파(Backpropagation)**로 레이어를 뒤로 다시 보내며 가중치와 편향을 조정합니다.

역전파와 가중치, 편향이란 생소한 용어가 갑자기 등장했는데요.
중요한 용어이기 때문에 잠깐 짚고 넘어가겠습니다.

---

#### 가중치와 편향
##### weight and bias

가중치는 각 입력값이 출력값에 미치는 중요도를 조절하는 매개변수(parameter)입니다. 입력 값에 곱해지는 수이기 때문에, 입력으로 들어온 데이터들 중에서 중요한 특징은 많이 반영하고, 덜 중요한 특징은 덜 반영하게끔 조정해줍니다.

일차함수 y = ax + b 를 떠올립시다.
x는 입력값, y는 출력값이죠.
여기서 가중치는 a와 대응된다고 볼 수 있습니다.
즉 가중치를 조정한다는 것은, 함수의 기울기를 조정해서 특성마다 서로 차별점을 두는 것이죠.

그렇다면 b는 무엇에 대응될까요?
네, 편향입니다.
편향은 출력값이 일정 방향으로 치우치도록 하는 역할을 합니다.
따라서, 데이터를 더 잘 설명하기 위해 적절한 '오프셋'을 주는 식으로 조정하게 됩니다.

#### 역전파
##### backpropagation
 back이라는 것은 forward 도 있다는 소리겠죠?
네, 맞습니다. forward propagation, 순전파도 있습니다.
이 친구는 이전 계층을 기반으로 그냥 계산하고 출력값을 내놓는 친구입니다.
그런데, 역전파는 그 반대방향입니다.
역전파는 예측 오류를 계산하고 레이어를 뒤로 이동시켜 가중치를 조정하는 방식입니다.
다시 말해, 예측 결과를 개선하기 위해 신경망이 스스로 학습하는 과정은 순전파가 아닌 역전파에서 일어납니다.

실제 정답과 예측값과의 차이를 **오차 Loss** 라고 하는데요,
연쇄율 개념을 이용해 하나씩 거슬러 올라가서
'어떤 가중치에서 오차가 크게 벌어졌다.'
이런 걸 추적할 수 있는 알고리즘이 역전파라고 이해하시면 됩니다.
정말 쉽게 말하면, 역전파는 _피드백을 하는 과정_ 인거죠.

---

다시 딥러닝 얘기로 돌아와서,
딥러닝 모델에도 여러 종류가 있습니다.

그 중 몇 가지를 살펴보겠습니다.

### CNN  
#### Convolutional Neural Network  

CNN(합성곱 신경망)은 딥러닝 모델 중에서 **이미지 처리에 특화된 구조**입니다.  
이미지는 정말 중요한 데이터 자료형이지만, 컴퓨터가 인간처럼 즉시 알아보는 것은 쉽지 않죠.  
그래서 등장한 방법이 바로 **이미지 속 유용한 패턴을 자동으로 추출**하는 방식입니다.

이 핵심 과정은 다음과 같습니다:

1. 하나의 **작은 필터(커널)** 가 이미지 위를 슬라이딩하면서,  
2. 해당 영역의 픽셀값들과 필터 값을 곱해 모두 더해 하나의 숫자를 출력하고,  
3. 이 과정을 반복해 **특징 맵(feature map)**을 생성합니다.

예를 들어, 사람 얼굴 사진을 생각해봅시다.  
눈, 코, 입 같은 특징적인 요소들을 감지하는 다양한 필터들을 이미지에 적용합니다.  
눈 필터 → 눈 위치가 강조된 맵,  
코 필터 → 코 부분이 두드러지는 맵을 얻게 되죠.

이렇게 얻어진 여러 특징 맵들은 점점 더 복잡한 구조(예: 얼굴 전체)를 인식할 수 있게끔 조합됩니다.  
CNN은 간단한 선, 곡선 같은 저차원 특징에서 출발해,  
**합성처럼 고차원의 개념을 추론하는 구조**를 갖는 것이 특징입니다.

### RNN  
#### Recurrent Neural Network

우리 주변엔 시간의 흐름에 따라 변화하는 데이터들이 많습니다.  
예를 들어 **문장, 음성, 주식 가격, 센서 데이터** 등이 그렇죠.  
이런 시퀀스 데이터를 처리하기 위해 만들어진 구조가 바로 **순환 신경망 RNN**입니다.

RNN의 가장 큰 특징은, **이전의 출력을 다시 다음 입력과 함께 사용한다는 점**입니다.  
즉, 현재 입력 + 과거 정보를 함께 고려해 출력을 내는 구조죠.

이전의 정보(= 은닉 상태)를 다음 단계로 넘겨주며,  
일종의 “기억”을 가진 것처럼 작동합니다.

하지만 RNN은 시간이 길어질수록 옛날 정보는 점점 잊어버리는 문제가 있습니다.  
이를 **장기 의존성 문제(long-term dependency problem)**라고 합니다.

---

### LSTM  
#### Long Short-Term Memory

LSTM은 이런 RNN의 단점을 해결하기 위해 고안된 구조입니다.  
'Long Short-Term Memory'라는 이름처럼, **짧은 기억과 긴 기억을 모두 다룰 수 있는** 구조를 가지고 있죠.

핵심은 **셀 상태(cell state)**라는 개념입니다.  
이 셀 상태는 일종의 ‘기억 저장 공간’이고,  
여기에 정보를 얼마나 넣고, 얼마나 빼고, 얼마나 출력할지를  
**게이트(Gate)** 라는 구조로 조절합니다.

- 입력 게이트: 현재 입력을 얼마나 기억할지 결정  
- 삭제 게이트: 기존 기억을 얼마나 지울지 결정  
- 출력 게이트: 다음 출력에 어느 정보를 반영할지 결정  

이렇게 조절 가능한 기억 덕분에, LSTM은 **장기적인 맥락도 잘 기억**할 수 있습니다.

예를 들어 문장:  
> "나는 오늘 아침에 일어나서 밥을 먹고 학교에 갔다. 그리고 나서 **책을 펴고**..."

이런 문맥에서 “펴고”라는 단어가 나오기 위해선 “책”이라는 단어가 기억돼 있어야 하죠.  
이런 문맥 기억이 바로 LSTM의 강점입니다.

하지만 이 LSTM도 텍스트가 매우 길어지면, 초반의 단어들을 기억하는 데 한계가 있습니다.
왜냐하면 여전히 정보를 순차적으로 전달받는 구조이기 때문에, 시간이 지나며 기억이 희석되거나 덮어쓰기가 발생할 수 있거든요.
기억 저장 공간(셀 상태)이 생기긴 했지만, 결국 RNN 계열의 구조적 제약에서 완전히 자유롭지는 않습니다.

그래서 탄생한 것이 **트랜스포머**입니다.
~~무대를 완전히 뒤집어놓으셨다...~~

---
### 트랜스포머
#### Transformer

RNN이나 LSTM은 시퀀스 데이터를 잘 다루긴 했지만, **한 번에 한 토큰씩 처리해야 하는 구조적 한계**가 있었습니다.  
문장이 길어질수록 앞의 정보를 기억하기 어렵고, 계산 속도도 느려지죠.

Transformer는 이 문제를 근본적으로 해결한 모델입니다.  
2017년, 구글에서 발표한 논문 **〈Attention Is All You Need〉**에서 처음 소개되었고,  
지금 우리가 알고 있는 **ChatGPT, BERT, T5** 같은 모델들의 **기반 구조**가 되었습니다.


#### 핵심 아이디어는 Attention

Transformer는 RNN처럼 **순서대로** 처리하지 않습니다.  
대신, **문장 전체를 한꺼번에 보고**,  
각 단어가 **다른 단어들과 얼마나 관련 있는지를 계산**해서 처리합니다.  
이게 바로 **Self-Attention** 메커니즘입니다.

> 예:  
> 문장: "나는 사과를 먹었다. 그리고 그것은 맛있었다."  
> 여기서 "그것"이 가리키는 게 "사과"라는 걸 알려면, "사과"와 "그것" 사이의 **연결(Attention)**을 모델이 계산해낼 수 있어야 하죠.

Self-Attention은 이런 연관성을 **수치화해서 반영**합니다.  
즉, 단어들 간의 관계를 고려해 각 단어의 **의미 표현(embedding)**을 조정하는 겁니다.

> ### 여기서 잠깐!
> #### 임베딩 embedding 이란?
>텍스트 데이터를 모델이 이해할 수 있는 **숫자 벡터 형태로 바꾸는 과정**.
>각 단어를 고차원 공간의 점으로 표현하고, 의미가 비슷한 단어끼리는 **서로 가까운 위치에 배치**시킨다.


---

### 구조 요약

Transformer는 크게 두 부분으로 구성됩니다:

1. **인코더(Encoder)**: 전체 입력 문장을 처리하여 의미를 추출  
2. **디코더(Decoder)**: 인코더가 만든 정보를 바탕으로 문장을 생성

GPT는 **디코더만 사용**하고, BERT는 **인코더만 사용**합니다.
두 구조는 서로 반대 방향으로 작동하며, **GPT는 생성에, BERT는 이해에 강점**을 가집니다.

_인코딩과 디코딩의 차이_
>예를 들어, 저희가 국어 비문학 지문을 읽는다고 합시다.
먼저 지문을 꼼꼼히 읽고, 중요한 단어와 문장에 형광펜을 칠하거나 밑줄을 긋는 작업이 인코딩입니다.
이 과정에서 우리는 단어 하나하나가 어떤 문맥 속에 있는지를 고려하게 되죠.

> 그리고 나서, 그렇게 추려낸 핵심 표현들을 바탕으로 누군가에게 이 내용을 다시 설명해주거나 요약문을 작성하는 과정이 디코딩입니다.

> 즉, 인코딩은 "문장의 의미를 뽑아내는 과정", 디코딩은 "그 의미를 바탕으로 새로운 문장을 만들어내는 과정"이라 볼 수 있죠.

각 블록 내부엔 다음과 같은 구조가 반복됩니다:

- **Self-Attention**: 단어들 간의 관련성 계산  
- **Feedforward Network**: 각 단어별 정보 처리  
- **Residual Connection** + **Layer Normalization**: 안정적 학습을 위한 구조


트랜스포머는 병렬처리가 가능해 GPU 활용을 극대화할 수 있습니다. 긴 문맥도 효과적으로 처리할 수 있고요. 

---


오늘은 제가 처음으로 AI 를 공부하면서 알게 된 개념들을 정리해보는 시간을 가졌습니다.
아직 배워야 할 것 투성이지만, 열심히 공부해봐야죠.
가던 길 가겠습니다. 감사합니다.


